{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append('src/')\n",
    "\n",
    "from smiles_lstm.model.smiles_vocabulary import SMILESTokenizer, Vocabulary, create_vocabulary\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import warnings\n",
    "# ignore some deprecation warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(tokenizer_array, desired_length):\n",
    "    padded_sequence = pad_sequences([tokenizer_array], maxlen=desired_length, padding='post')[0]\n",
    "    return padded_sequence\n",
    "\n",
    "def preprocess_smiles_data(x):\n",
    "    x = tk.tokenize(x)\n",
    "    x = vocabulary.encode(x )\n",
    "    x  = pad_sequence(x, 200 )\n",
    "    x  = torch.tensor([x ])\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load main data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('retrosynthesis-all', header=None)\n",
    "df['source'] = df[0].apply(lambda x: x.split('>>')[0])\n",
    "df['target'] = df[0].apply(lambda x: x.split('>>')[1])\n",
    "df.drop(0, axis=1, inplace=True)\n",
    "\n",
    "# Remove spaces from all columns\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define `Tokenizer` and `Vocabulary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset that takes a file containing \\n separated SMILES.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, smiles_list : list, vocabulary : Vocabulary,\n",
    "                 tokenizer : SMILESTokenizer) -> None:\n",
    "        self._vocabulary  = vocabulary\n",
    "        self._tokenizer   = tokenizer\n",
    "        self._smiles_list = list(smiles_list)\n",
    "\n",
    "    def __getitem__(self, i : int) -> torch.Tensor:\n",
    "        smi     = self._smiles_list[i]\n",
    "        tokens  = self._tokenizer.tokenize(smi)\n",
    "        encoded = self._vocabulary.encode(tokens)\n",
    "        return torch.tensor(encoded.astype(int), dtype=torch.long)  # pylint: disable=E1102\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._smiles_list)\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(encoded_seqs : list) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Converts a list of encoded sequences into a padded tensor.\n",
    "        \"\"\"\n",
    "        max_length   = max([seq.size(0) for seq in encoded_seqs])\n",
    "        collated_arr = torch.zeros(len(encoded_seqs),\n",
    "                                   max_length,\n",
    "                                   dtype=torch.long)  # padded with zeros\n",
    "        for i, seq in enumerate(encoded_seqs):\n",
    "            collated_arr[i, :seq.size(0)] = seq\n",
    "        return collated_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 85 unique tokens in the vocabulary.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a vocabulary using all SMILES in df\n",
    "dataset = df['source'].unique().tolist() + df['target'].unique().tolist()\n",
    "dataset = np.unique(dataset).tolist()\n",
    "\n",
    "tokenizer = SMILESTokenizer()\n",
    "vocabulary   = create_vocabulary(smiles_list=dataset, tokenizer=tokenizer, canonical=True)\n",
    "print(f'There are {len(vocabulary)} unique tokens in the vocabulary.\\n')\n",
    "\n",
    "train_dataset = Dataset(smiles_list=df['source'].tolist(), vocabulary=vocabulary, tokenizer=tokenizer)\n",
    "train_dataset = train_dataset.collate_fn(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 160])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[22].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.tensor([[21, 21, 20]]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / validation / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45033, 2)\n",
      "Train data size: 36026\n",
      "Validation data size: 7205\n",
      "Test data size: 1802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "# Splitting the data into train and combined val/test sets\n",
    "train_data, val_test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitting the combined val/test set into separate val and test sets\n",
    "val_data, test_data = train_test_split(val_test_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Printing the sizes of the resulting splits\n",
    "print(\"Train data size:\", len(train_data))\n",
    "print(\"Validation data size:\", len(val_data))\n",
    "print(\"Test data size:\", len(test_data))\n",
    "\n",
    "train     = train_data.copy()\n",
    "test      = test_data.copy()\n",
    "valid     = val_data.copy()\n",
    "\n",
    "train_X = Dataset(smiles_list=train['source'].tolist(), vocabulary=vocabulary, tokenizer=tokenizer)\n",
    "train_X = train_X.collate_fn(train_X)\n",
    "train_y = Dataset(smiles_list=train['target'].tolist(), vocabulary=vocabulary, tokenizer=tokenizer)\n",
    "train_y = train_y.collate_fn(train_y)\n",
    "\n",
    "val_X = Dataset(smiles_list=train['source'].tolist(), vocabulary=vocabulary, tokenizer=tokenizer)\n",
    "val_X = val_X.collate_fn(val_X)\n",
    "val_y = Dataset(smiles_list=train['target'].tolist(), vocabulary=vocabulary, tokenizer=tokenizer)\n",
    "val_y = val_y.collate_fn(val_y)\n",
    "\n",
    "test_X = Dataset(smiles_list=train['source'].tolist(), vocabulary=vocabulary, tokenizer=tokenizer)\n",
    "test_X = test_X.collate_fn(test_X)\n",
    "test_y = Dataset(smiles_list=train['target'].tolist(), vocabulary=vocabulary, tokenizer=tokenizer)\n",
    "test_y = test_y.collate_fn(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmilesLSTM(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, num_layers, dropout=0, hidden_layers=5):\n",
    "        super(SmilesLSTM, self).__init__()\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_size = emb_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        # define models\n",
    "        self._embedding = nn.Embedding(num_embeddings=self.vocab_size,\n",
    "                               embedding_dim=self.emb_size)\n",
    "        \n",
    "        self._reccurent = nn.LSTM(input_size=self.emb_size,\n",
    "                          hidden_size=self.hidden_layers,\n",
    "                          num_layers=self.num_layers,\n",
    "                          dropout=self.dropout,\n",
    "                          batch_first=True)\n",
    "         \n",
    "        self._linear = nn.Linear(self.hidden_layers, self.vocab_size) # (batch size) x (sequence length) x (vocabulary size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(0)\n",
    "        \n",
    "        embedding = self._embedding(x)\n",
    "        rnn_output, (_, _) = self._reccurent(embedding)\n",
    "        linear = self._linear(rnn_output)\n",
    "        log_softmax = linear.log_softmax(dim=2)\n",
    "        output = log_softmax.argmax(dim=2).flatten().tolist()\n",
    "        return log_softmax, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmilesLSTM(vocab_size=len(vocabulary), emb_size=5, num_layers=1)\n",
    "log_softmax, output = model(train_X[99])\n",
    "y_true_smiles = train['target'].iloc[99]\n",
    "y_true_token = train_y[99].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, (correct_token, most_probable_token) in enumerate(zip(train['source'].iloc[99], y_pred)):\n",
    "#     print(f\"At time step {idx+1}, the generative model proposes {vocabulary.tokens()[most_probable_token]} as the most probable token and the correct token is {correct_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 160])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = torch.nn.NLLLoss(reduction='none')\n",
    "# print(f\"The output tensor from negative log-likelihood is:\\n{loss(log_softmax.transpose(1, 2), y_true_token)}\\n\")\n",
    "# loss(log_softmax.transpose(1, 2), y_true_token).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_X = torch.utils.data.DataLoader(train_X, batch_size=1, shuffle=True, collate_fn=Dataset.collate_fn)\n",
    "data_loader_y = torch.utils.data.DataLoader(train_y, batch_size=1, shuffle=True, collate_fn=Dataset.collate_fn)\n",
    "\n",
    "EPOCHS = 3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.NLLLoss(reduction='none')\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    for row in range(len(train_X)):\n",
    "        X = train_X[row]\n",
    "        y = train_y[row]\n",
    "        log_softmax, y_pred = model(X)\n",
    "        loss = loss_fn(log_softmax.transpose(1, 2), y.unsqueeze(0)).sum(dim=1)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14443</th>\n",
       "      <td>CC(C)N(C(=O)C[C@H]1C[C@@H](C=O)OC(C)(C)O1)C(C)C</td>\n",
       "      <td>CC(C)N(C(=O)C[C@H]1C[C@@H](CO)OC(C)(C)O1)C(C)C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                source  \\\n",
       "14443  CC(C)N(C(=O)C[C@H]1C[C@@H](C=O)OC(C)(C)O1)C(C)C   \n",
       "\n",
       "                                               target  \n",
       "14443  CC(C)N(C(=O)C[C@H]1C[C@@H](CO)OC(C)(C)O1)C(C)C  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1, 20, 20, 25, 20,  3, 17, 25,  4, 81,  8, 82, 81,  3, 20, 20,  3, 20,\n",
       "          4, 20,  4, 81,  9, 82, 81,  3,  5, 81, 10, 81, 81, 81, 81, 81, 10,  4,\n",
       "         84, 81,  9, 81,  8, 25,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " tensor([ 1, 20, 17, 20,  3, 20,  4, 20, 81,  8, 82, 81,  3, 20,  3, 17, 25,  4,\n",
       "         25, 20, 20,  4, 81,  3, 25,  4, 81,  9, 84, 81,  3,  5, 81, 10, 81, 81,\n",
       "         81, 81, 81, 10,  4, 82, 81,  8,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]))"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[0], test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, y_pred = model(test_X[0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
